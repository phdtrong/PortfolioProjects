{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOY1DsPbH+foI3qJfo4US4m",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/phdtrong/PortfolioProjects/blob/phdtrong-patch-main-portfolio/project10/StockPricePrediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "p6qpIz-AYAcy"
      },
      "outputs": [],
      "source": [
        "#Library importing\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime as dt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Training Setting\n",
        "split_ratio = 0.5\n",
        "stock = ['TSLA']\n",
        "\n",
        "#Fetch the data - Select date range\n",
        "import yfinance as yf\n",
        "data = yf.download(stock, period='max')\n",
        "data.reset_index(inplace=True)\n",
        "\n",
        "#Select filter condition\n",
        "data_close_price = data['Adj Close']"
      ],
      "metadata": {
        "id": "mTl_Itj5mtYn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04160ecf-7333-4cf8-a983-6a211a81fc60"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[*********************100%%**********************]  1 of 1 completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define train and test data set\n",
        "split_size = (int)(split_ratio * data_close_price.size)\n",
        "train_data = data_close_price[:split_size]\n",
        "test_data = data_close_price[split_size:]\n",
        "#type(train_data)\n",
        "\n",
        "#Normalize data\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "train_data = train_data.values.reshape(-1,1) #single column, multiple rows\n",
        "test_data = test_data.values.reshape(-1,1) #single column, multiple rows"
      ],
      "metadata": {
        "id": "AvDv14MgsDCp"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the Scaler with training data and smooth data\n",
        "smoothing_window_size = (int)(split_size / 4)\n",
        "even_window_size = data_close_price.size - (int)(data_close_price.size % smoothing_window_size)\n",
        "\n",
        "for di in range(0,split_size,smoothing_window_size):\n",
        "    scaler.fit(train_data[di:di+smoothing_window_size,:])\n",
        "    train_data[di:di+smoothing_window_size,:] = scaler.transform(train_data[di:di+smoothing_window_size,:])\n",
        "\n",
        "# You normalize the last bit of remaining data\n",
        "if(data_close_price.size % smoothing_window_size > 0):\n",
        "  scaler.fit(train_data[di+smoothing_window_size:,:])\n",
        "  train_data[di+smoothing_window_size:,:] = scaler.transform(train_data[di+smoothing_window_size:,:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "id": "G5fce5xru0kh",
        "outputId": "80aaaef1-cab1-41f0-92fd-4b617c4afa14"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-136-9d2fa8514e34>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msplit_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msmoothing_window_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mdi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0msmoothing_window_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mdi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0msmoothing_window_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mdi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0msmoothing_window_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: too many indices for array: array is 1-dimensional, but 2 were indexed"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape both train and test data\n",
        "train_data = train_data.reshape(-1)\n",
        "\n",
        "# Normalize test data\n",
        "test_data = test_data.reshape(-1)"
      ],
      "metadata": {
        "id": "G77PoeHQu3vG"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now perform exponential moving average smoothing\n",
        "# So the data will have a smoother curve than the original ragged data\n",
        "EMA = 0.0\n",
        "gamma = 0.1\n",
        "for ti in range(split_size):\n",
        "  EMA = gamma*train_data[ti] + (1-gamma)*EMA\n",
        "  train_data[ti] = EMA\n",
        "\n",
        "# Used for visualization and test purposes\n",
        "all_mid_data = np.concatenate([train_data,test_data],axis=0)"
      ],
      "metadata": {
        "id": "GDwmXy01mjHg"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "window_size = 100\n",
        "N = train_data.size\n",
        "std_avg_predictions = []\n",
        "std_avg_x = []\n",
        "mse_errors = []\n",
        "\n",
        "for pred_idx in range(window_size,N):\n",
        "\n",
        "    if pred_idx >= N:\n",
        "        date = dt.datetime.strptime(k, '%Y-%m-%d').date() + dt.timedelta(days=1)\n",
        "    else:\n",
        "        date = data.loc[pred_idx,'Date']\n",
        "\n",
        "    std_avg_predictions.append(np.mean(train_data[pred_idx-window_size:pred_idx]))\n",
        "    mse_errors.append((std_avg_predictions[-1]-train_data[pred_idx])**2)\n",
        "    std_avg_x.append(date)\n",
        "\n",
        "print('MSE error for standard averaging: %.5f'%(0.5*np.mean(mse_errors)))"
      ],
      "metadata": {
        "id": "OjB11HaevDHx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}